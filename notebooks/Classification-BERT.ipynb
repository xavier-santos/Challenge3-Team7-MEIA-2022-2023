{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df951474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\carol\\anaconda3\\envs\\Mestrado\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train loss: 0.5006270631216466\n",
      "Epoch 1/5 | Test loss: 0.435180227458477\n",
      "Epoch 2/5 | Train loss: 0.40478939963504673\n",
      "Epoch 2/5 | Test loss: 0.39761337377130984\n",
      "Epoch 3/5 | Train loss: 0.3467337834648788\n",
      "Epoch 3/5 | Test loss: 0.37180393375456333\n",
      "Epoch 4/5 | Train loss: 0.30355998980812726\n",
      "Epoch 4/5 | Test loss: 0.3579508002847433\n",
      "Epoch 5/5 | Train loss: 0.27615680997259917\n",
      "Epoch 5/5 | Test loss: 0.3555926736444235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('../data/balanced_train.csv')\n",
    "\n",
    "test_data = pd.read_csv('../data/balanced_test.csv')\n",
    "\n",
    "\n",
    "genre_columns = train_data.columns.drop(['Name', 'Description Tokenized'])\n",
    "\n",
    "# Tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Hiperparâmetros\n",
    "max_len = 40\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Classe Dataset personalizada\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Description Tokenized']\n",
    "        labels = self.data.iloc[idx][genre_columns]\n",
    "\n",
    "        tokens = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokens['input_ids'][0],\n",
    "            'attention_mask': tokens['attention_mask'][0],\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Função de perda de entropia cruzada binária\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def evaluate(model, data_loader, loss_fn, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.sigmoid(logits).cpu().numpy())\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Preparar os DataLoaders\n",
    "train_dataset = MovieDataset(train_data, tokenizer, max_len)\n",
    "test_dataset = MovieDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Carreguar o modelo pré-treinado e modifique a camada de saída\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=9).to(device)\n",
    "model.classifier = nn.Linear(model.config.hidden_size, 9).to(device)\n",
    "\n",
    "# Otimizador e programador\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Treinamento e avaliação\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train loss: {train_loss}\")\n",
    "\n",
    "    test_loss = evaluate(model, test_loader, loss_fn, device)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Test loss: {test_loss}\")\n",
    "\n",
    "# previsões no conjunto de teste\n",
    "predictions = predict(model, test_loader, device)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54fdd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro: 0.6980843183987057\n",
      "F1 Samples: 0.6809393601190477\n"
     ]
    }
   ],
   "source": [
    "# Avalie o desempenho do modelo usando a métrica F1\n",
    "test_labels = test_data[genre_columns].values  # Ajuste de acordo com os gêneros no seu conjunto de dados\n",
    "f1_macro = f1_score(test_labels, predictions_binary, average='macro')\n",
    "f1_samples = f1_score(test_labels, predictions_binary, average='samples')\n",
    "\n",
    "print(f\"F1 Macro: {f1_macro}\")\n",
    "print(f\"F1 Samples: {f1_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb68e86c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Comedy       0.71      0.62      0.67       487\n",
      "                  Crime       0.81      0.72      0.76       271\n",
      "                  Drama       0.76      0.77      0.77       613\n",
      "                Romance       0.68      0.55      0.61       270\n",
      "   Action and Adventure       0.78      0.73      0.75       463\n",
      "Documentary and History       0.73      0.65      0.69       172\n",
      "   Family and Animation       0.76      0.69      0.72       275\n",
      "     Fantasy and Sci-Fi       0.71      0.65      0.68       259\n",
      "    Horror and Thriller       0.68      0.61      0.64       309\n",
      "\n",
      "              micro avg       0.74      0.68      0.71      3119\n",
      "              macro avg       0.73      0.67      0.70      3119\n",
      "           weighted avg       0.74      0.68      0.71      3119\n",
      "            samples avg       0.74      0.68      0.68      3119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Supondo que test_labels seja um numpy array contendo os rótulos verdadeiros do conjunto de teste\n",
    "report = classification_report(test_labels, predictions_binary, target_names=genre_columns, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f11977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     genre    AUC-PR   AUC-ROC\n",
      "0                   Comedy  0.740795  0.823585\n",
      "1                    Crime  0.816305  0.916625\n",
      "2                    Drama  0.817795  0.848038\n",
      "3                  Romance  0.641997  0.864283\n",
      "4     Action and Adventure  0.826346  0.887924\n",
      "5  Documentary and History  0.742287  0.930621\n",
      "6     Family and Animation  0.763771  0.903410\n",
      "7       Fantasy and Sci-Fi  0.727925  0.897939\n",
      "8      Horror and Thriller  0.693512  0.862318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "\n",
    "pr_curves = {}\n",
    "roc_curves = {}\n",
    "for i, genre in enumerate(genre_columns):\n",
    "    precision, recall, _ = precision_recall_curve(test_labels[:, i], predictions[:, i])\n",
    "    fpr, tpr, _ = roc_curve(test_labels[:, i], predictions[:, i])\n",
    "    pr_curves[genre] = (precision, recall)\n",
    "    roc_curves[genre] = (fpr, tpr)\n",
    "    \n",
    "auc_pr = []\n",
    "auc_roc = []\n",
    "for i, genre in enumerate(genre_columns):\n",
    "    ap = auc(pr_curves[genre][1], pr_curves[genre][0])\n",
    "    ar = auc(roc_curves[genre][0], roc_curves[genre][1])\n",
    "    auc_pr.append(ap)\n",
    "    auc_roc.append(ar)\n",
    "\n",
    "results = pd.DataFrame({'genre': genre_columns, 'AUC-PR': auc_pr, 'AUC-ROC': auc_roc})\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919c55dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusão para Comedy:\n",
      "[[671 122]\n",
      " [183 304]]\n",
      "\n",
      "Matriz de confusão para Crime:\n",
      "[[962  47]\n",
      " [ 76 195]]\n",
      "\n",
      "Matriz de confusão para Drama:\n",
      "[[520 147]\n",
      " [139 474]]\n",
      "\n",
      "Matriz de confusão para Romance:\n",
      "[[939  71]\n",
      " [122 148]]\n",
      "\n",
      "Matriz de confusão para Action and Adventure:\n",
      "[[721  96]\n",
      " [125 338]]\n",
      "\n",
      "Matriz de confusão para Documentary and History:\n",
      "[[1067   41]\n",
      " [  61  111]]\n",
      "\n",
      "Matriz de confusão para Family and Animation:\n",
      "[[944  61]\n",
      " [ 86 189]]\n",
      "\n",
      "Matriz de confusão para Fantasy and Sci-Fi:\n",
      "[[954  67]\n",
      " [ 91 168]]\n",
      "\n",
      "Matriz de confusão para Horror and Thriller:\n",
      "[[880  91]\n",
      " [119 190]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "# Calcular e imprimir matriz de confusão para cada gênero\n",
    "for i, genre in enumerate(genre_columns):\n",
    "    cm = confusion_matrix(test_labels[:, i], predictions_binary[:, i])\n",
    "    print(f'\\nMatriz de confusão para {genre}:')\n",
    "    print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
