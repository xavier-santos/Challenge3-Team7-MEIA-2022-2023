{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6674ffe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 200s 1s/step - loss: 0.4806 - accuracy: 0.3445 - val_loss: 0.4251 - val_accuracy: 0.4086\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 165s 1s/step - loss: 0.3994 - accuracy: 0.4172 - val_loss: 0.3978 - val_accuracy: 0.4605\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 175s 1s/step - loss: 0.3268 - accuracy: 0.5645 - val_loss: 0.3984 - val_accuracy: 0.4921\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 166s 1s/step - loss: 0.2583 - accuracy: 0.6483 - val_loss: 0.4300 - val_accuracy: 0.4718\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 169s 1s/step - loss: 0.2036 - accuracy: 0.6749 - val_loss: 0.4632 - val_accuracy: 0.4492\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 175s 1s/step - loss: 0.1655 - accuracy: 0.6912 - val_loss: 0.4904 - val_accuracy: 0.4379\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 178s 1s/step - loss: 0.1330 - accuracy: 0.7040 - val_loss: 0.5463 - val_accuracy: 0.4605\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 173s 1s/step - loss: 0.1060 - accuracy: 0.6889 - val_loss: 0.5802 - val_accuracy: 0.4402\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 155s 1s/step - loss: 0.0844 - accuracy: 0.6922 - val_loss: 0.6215 - val_accuracy: 0.4492\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 166s 1s/step - loss: 0.0677 - accuracy: 0.6856 - val_loss: 0.6728 - val_accuracy: 0.4289\n",
      "41/41 [==============================] - 17s 402ms/step - loss: 0.7386 - accuracy: 0.4026\n",
      "Loss: 0.738593578338623\n",
      "Accuracy: 0.4026479721069336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Pré-processar os dados\n",
    "# Carregue seus datasets balanceados\n",
    "train_data = pd.read_csv('../data/preprocessed/movies_genres_grouped_train_preprocessed.csv')\n",
    "test_data = pd.read_csv('../data/preprocessed/movies_genres_grouped_test_preprocessed.csv')\n",
    "\n",
    "category_columns = train_data.columns.drop(['Name', 'Description', 'Combined'])\n",
    "\n",
    "# Defina os parâmetros de pré-processamento\n",
    "max_features = 10000  # Número máximo de palavras a serem usadas (palavras mais frequentes)\n",
    "maxlen = 200  # Número máximo de palavras no texto\n",
    "\n",
    "# Tokenize os textos\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_data['Combined'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Combined'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Combined'])\n",
    "\n",
    "# Padronize os textos\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Obtenha os labels one-hot encoded\n",
    "y_train = train_data[category_columns].values\n",
    "y_test = test_data[category_columns].values\n",
    "\n",
    "# 2. Construir o modelo\n",
    "embedding_dim = 128  # Dimensão do vetor de embedding\n",
    "lstm_units = 64  # Unidades LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_features, embedding_dim, input_length=maxlen),\n",
    "    Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "    Bidirectional(LSTM(lstm_units)),\n",
    "    Dense(len(category_columns), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 3. Treinar o modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affa0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 9s 177ms/step\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Comedy       0.62      0.50      0.55       502\n",
      "                  Crime       0.65      0.53      0.58       259\n",
      "                  Drama       0.73      0.76      0.74       757\n",
      "                Romance       0.54      0.33      0.41       272\n",
      "   Action and Adventure       0.64      0.54      0.59       450\n",
      "Documentary and History       0.47      0.32      0.38       144\n",
      "   Family and Animation       0.48      0.30      0.37       141\n",
      "     Fantasy and Sci-Fi       0.52      0.38      0.44       154\n",
      "    Horror and Thriller       0.51      0.45      0.48       291\n",
      "\n",
      "              micro avg       0.63      0.53      0.57      2970\n",
      "              macro avg       0.57      0.46      0.50      2970\n",
      "           weighted avg       0.62      0.53      0.57      2970\n",
      "            samples avg       0.65      0.55      0.56      2970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prever e converter as previsões para o formato binarizado\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binarized = np.round(y_pred)\n",
    "\n",
    "# Calcular e exibir métricas de avaliação\n",
    "report = classification_report(y_test, y_pred_binarized, target_names=category_columns, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1132640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 9s 222ms/step\n",
      "F1-score (micro): 0.57\n",
      "F1-score (macro): 0.50\n",
      "Precision (micro): 0.63\n",
      "Precision (macro): 0.57\n",
      "Recall (micro): 0.53\n",
      "Recall (macro): 0.46\n",
      "41/41 [==============================] - 10s 247ms/step\n",
      "Class: Comedy\n",
      "F1-score: 0.55\n",
      "AUC-PR: 0.63\n",
      "\n",
      "\n",
      "Class: Crime\n",
      "F1-score: 0.58\n",
      "AUC-PR: 0.63\n",
      "\n",
      "\n",
      "Class: Drama\n",
      "F1-score: 0.74\n",
      "AUC-PR: 0.77\n",
      "\n",
      "\n",
      "Class: Romance\n",
      "F1-score: 0.41\n",
      "AUC-PR: 0.46\n",
      "\n",
      "\n",
      "Class: Action and Adventure\n",
      "F1-score: 0.59\n",
      "AUC-PR: 0.66\n",
      "\n",
      "\n",
      "Class: Documentary and History\n",
      "F1-score: 0.38\n",
      "AUC-PR: 0.39\n",
      "\n",
      "\n",
      "Class: Family and Animation\n",
      "F1-score: 0.37\n",
      "AUC-PR: 0.39\n",
      "\n",
      "\n",
      "Class: Fantasy and Sci-Fi\n",
      "F1-score: 0.44\n",
      "AUC-PR: 0.39\n",
      "\n",
      "\n",
      "Class: Horror and Thriller\n",
      "F1-score: 0.48\n",
      "AUC-PR: 0.50\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve, precision_score, recall_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-score (micro): {:.2f}\".format(f1_micro))\n",
    "print(\"F1-score (macro): {:.2f}\".format(f1_macro))\n",
    "print(\"Precision (micro): {:.2f}\".format(precision_micro))\n",
    "print(\"Precision (macro): {:.2f}\".format(precision_macro))\n",
    "print(\"Recall (micro): {:.2f}\".format(recall_micro))\n",
    "print(\"Recall (macro): {:.2f}\".format(recall_macro))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "f1_scores_per_class = f1_score(y_test, np.round(y_pred), average=None)\n",
    "auc_pr_per_class = average_precision_score(y_test, y_pred, average=None)\n",
    "for i, category in enumerate(category_columns):\n",
    "    print(\"Class: {}\".format(category))\n",
    "    print(\"F1-score: {:.2f}\".format(f1_scores_per_class[i]))\n",
    "    print(\"AUC-PR: {:.2f}\".format(auc_pr_per_class[i]))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
