{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35a6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "160/160 - 69s - loss: 0.5638 - accuracy: 0.2670 - val_loss: 0.5586 - val_accuracy: 0.2648 - 69s/epoch - 432ms/step\n",
      "Epoch 2/15\n",
      "160/160 - 57s - loss: 0.5580 - accuracy: 0.2649 - val_loss: 0.5577 - val_accuracy: 0.2648 - 57s/epoch - 359ms/step\n",
      "Epoch 3/15\n",
      "160/160 - 54s - loss: 0.5406 - accuracy: 0.2745 - val_loss: 0.5178 - val_accuracy: 0.3141 - 54s/epoch - 340ms/step\n",
      "Epoch 4/15\n",
      "160/160 - 46s - loss: 0.4960 - accuracy: 0.3147 - val_loss: 0.4963 - val_accuracy: 0.3195 - 46s/epoch - 287ms/step\n",
      "Epoch 5/15\n",
      "160/160 - 42s - loss: 0.4568 - accuracy: 0.3405 - val_loss: 0.4679 - val_accuracy: 0.3242 - 42s/epoch - 261ms/step\n",
      "Epoch 6/15\n",
      "160/160 - 48s - loss: 0.4124 - accuracy: 0.3659 - val_loss: 0.4455 - val_accuracy: 0.3781 - 48s/epoch - 297ms/step\n",
      "Epoch 7/15\n",
      "160/160 - 55s - loss: 0.3722 - accuracy: 0.3843 - val_loss: 0.4453 - val_accuracy: 0.3625 - 55s/epoch - 341ms/step\n",
      "Epoch 8/15\n",
      "160/160 - 41s - loss: 0.3313 - accuracy: 0.3868 - val_loss: 0.4518 - val_accuracy: 0.3273 - 41s/epoch - 257ms/step\n",
      "Epoch 9/15\n",
      "160/160 - 44s - loss: 0.2961 - accuracy: 0.4292 - val_loss: 0.4330 - val_accuracy: 0.3641 - 44s/epoch - 277ms/step\n",
      "Epoch 10/15\n",
      "160/160 - 43s - loss: 0.2611 - accuracy: 0.4698 - val_loss: 0.4327 - val_accuracy: 0.4016 - 43s/epoch - 269ms/step\n",
      "Epoch 11/15\n",
      "160/160 - 43s - loss: 0.2235 - accuracy: 0.4917 - val_loss: 0.4270 - val_accuracy: 0.4203 - 43s/epoch - 267ms/step\n",
      "Epoch 12/15\n",
      "160/160 - 45s - loss: 0.1893 - accuracy: 0.4991 - val_loss: 0.4685 - val_accuracy: 0.3969 - 45s/epoch - 278ms/step\n",
      "Epoch 13/15\n",
      "160/160 - 48s - loss: 0.1595 - accuracy: 0.4964 - val_loss: 0.4884 - val_accuracy: 0.4430 - 48s/epoch - 302ms/step\n",
      "Epoch 14/15\n",
      "160/160 - 43s - loss: 0.1335 - accuracy: 0.4837 - val_loss: 0.5031 - val_accuracy: 0.3953 - 43s/epoch - 271ms/step\n",
      "Epoch 15/15\n",
      "160/160 - 46s - loss: 0.1096 - accuracy: 0.4790 - val_loss: 0.5481 - val_accuracy: 0.3539 - 46s/epoch - 286ms/step\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.5481 - accuracy: 0.3539\n",
      "Loss: 0.5480526089668274\n",
      "Accuracy: 0.3539062440395355\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, TimeDistributed, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "train_data = pd.read_csv('../data/balanced_train.csv')\n",
    "test_data = pd.read_csv('../data/balanced_test.csv')\n",
    "\n",
    "genre_columns = train_data.columns.drop(['Name', 'Description Tokenized'])\n",
    "\n",
    "# Tokenizar os textos\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(train_data['Description Tokenized']) + list(test_data['Description Tokenized']))\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Description Tokenized'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Description Tokenized'])\n",
    "\n",
    "maxlen = max(max([len(sequence) for sequence in X_train]), max([len(sequence) for sequence in X_test]))\n",
    "\n",
    "# Padronizar os textos\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "#labels one-hot encoded\n",
    "y_train = train_data[genre_columns].values\n",
    "y_test = test_data[genre_columns].values\n",
    "\n",
    "\n",
    "# modelo LSTM unidirecional\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embedding_dim, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(TimeDistributed(Dense(128, activation='relu')))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(Dense(len(genre_columns), activation='sigmoid'))\n",
    "\n",
    "# Compilar e treinar o modelo\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 15\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845f2d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 39ms/step\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Comedy       0.74      0.66      0.70       487\n",
      "                  Crime       0.82      0.73      0.77       271\n",
      "                  Drama       0.68      0.91      0.78       613\n",
      "                Romance       0.75      0.62      0.68       270\n",
      "   Action and Adventure       0.78      0.68      0.73       463\n",
      "Documentary and History       0.58      0.69      0.63       172\n",
      "   Family and Animation       0.70      0.65      0.68       275\n",
      "     Fantasy and Sci-Fi       0.70      0.66      0.68       259\n",
      "    Horror and Thriller       0.71      0.61      0.66       309\n",
      "\n",
      "              micro avg       0.72      0.71      0.71      3119\n",
      "              macro avg       0.72      0.69      0.70      3119\n",
      "           weighted avg       0.72      0.71      0.71      3119\n",
      "            samples avg       0.71      0.69      0.68      3119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binarized = np.round(y_pred)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binarized, target_names=genre_columns, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208623d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 39ms/step\n",
      "            AUC-PR   AUC-ROC\n",
      "micro     0.753540  0.884976\n",
      "macro     0.752009  0.872386\n",
      "weighted  0.756798  0.863066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Cálculo do AUC-PR e AUC-ROC geral\n",
    "auc_pr_micro = average_precision_score(y_test, y_pred_prob, average='micro')\n",
    "auc_pr_macro = average_precision_score(y_test, y_pred_prob, average='macro')\n",
    "auc_pr_weighted = average_precision_score(y_test, y_pred_prob, average='weighted')\n",
    "\n",
    "auc_roc_micro = roc_auc_score(y_test, y_pred_prob, average='micro')\n",
    "auc_roc_macro = roc_auc_score(y_test, y_pred_prob, average='macro')\n",
    "auc_roc_weighted = roc_auc_score(y_test, y_pred_prob, average='weighted')\n",
    "\n",
    "# Criação da tabela\n",
    "data = {'AUC-PR': [auc_pr_micro, auc_pr_macro, auc_pr_weighted],\n",
    "        'AUC-ROC': [auc_roc_micro, auc_roc_macro, auc_roc_weighted]}\n",
    "index = ['micro', 'macro', 'weighted']\n",
    "results = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Exibição dos resultados\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ddcb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     genre    AUC-PR   AUC-ROC\n",
      "0                   Comedy  0.780158  0.844090\n",
      "1                    Crime  0.816230  0.911106\n",
      "2                    Drama  0.749322  0.815749\n",
      "3                  Romance  0.740574  0.890854\n",
      "4     Action and Adventure  0.796595  0.866368\n",
      "5  Documentary and History  0.722892  0.891482\n",
      "6     Family and Animation  0.748108  0.880988\n",
      "7       Fantasy and Sci-Fi  0.721744  0.888144\n",
      "8      Horror and Thriller  0.685137  0.862691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "pr_curves = {}\n",
    "roc_curves = {}\n",
    "for i, genre in enumerate(genre_columns):\n",
    "    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_prob[:, i])\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, i], y_pred_prob[:, i])\n",
    "    pr_curves[genre] = (precision, recall)\n",
    "    roc_curves[genre] = (fpr, tpr)\n",
    "    \n",
    "auc_pr = []\n",
    "auc_roc = []\n",
    "for i, genre in enumerate(genre_columns):\n",
    "    ap = auc(pr_curves[genre][1], pr_curves[genre][0])\n",
    "    ar = auc(roc_curves[genre][0], roc_curves[genre][1])\n",
    "    auc_pr.append(ap)\n",
    "    auc_roc.append(ar)\n",
    "\n",
    "results = pd.DataFrame({'genre': genre_columns, 'AUC-PR': auc_pr, 'AUC-ROC': auc_roc})\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
