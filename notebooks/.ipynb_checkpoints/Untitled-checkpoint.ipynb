{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0ab768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def tokenize_input(user_input):\n",
    "    user_input = RegexpTokenizer(r'[a-zA-z]+').tokenize(user_input)\n",
    "    user_input = [t.lower() for t in user_input]\n",
    "    user_input = [t for t in user_input if not t in list(string.punctuation)]\n",
    "    user_input = [t for t in user_input if not t in stopwords.words(\"english\")]\n",
    "    user_input = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in user_input]\n",
    "    return inputa\n",
    "\n",
    "movies_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Create a bag-of-words representation for each movie description\n",
    "vectorizer = CountVectorizer()\n",
    "movie_bow = vectorizer.fit_transform(movies_df['Description Tokenized'])\n",
    "\n",
    "# Get user input description\n",
    "user_input = 'An ambitious young executive chooses a'\n",
    "\n",
    "user_tokenized_input = tokenize_input(user_input)\n",
    "\n",
    "# Create a bag-of-words representation for the user input description\n",
    "user_input_bow = vectorizer.transform(user_tokenized_input)\n",
    "\n",
    "# Calculate similarity between user input description and each movie description\n",
    "similarity_scores = cosine_similarity(user_input_bow, movie_bow)\n",
    "\n",
    "# Rank movies based on similarity\n",
    "ranked_movies = movies_df.iloc[similarity_scores[0].argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbac7a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adult</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Short</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Talk-Show</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Description Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>Heatwave</td>\n",
       "      <td>17/01/2022</td>\n",
       "      <td>Claire, an ambitious young woman, starts worki...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['claire', 'ambitious', 'young', 'woman', 'sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Vanity Fair: Killers Kill, Dead Men Die</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most ambitious portfolio in the thirteen-y...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>257.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ambitious', 'portfolio', 'thirteen', 'year',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7366</th>\n",
       "      <td>Rogue Trader</td>\n",
       "      <td>27/10/2021</td>\n",
       "      <td>Ambitious investment banker Tom Walker is cata...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ambitious', 'investment', 'banker', 'tom', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>My Beautiful Laundrette</td>\n",
       "      <td>03/02/1989</td>\n",
       "      <td>An ambitious Pakistani Briton and his white bo...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>16522.0</td>\n",
       "      <td>M/16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ambitious', 'pakistani', 'briton', 'white', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>The Caddy</td>\n",
       "      <td>03/03/2021</td>\n",
       "      <td>When an ambitious young Mexican diplomat loses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ambitious', 'young', 'mexican', 'diplomat', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Paris Trout</td>\n",
       "      <td>29/11/1991</td>\n",
       "      <td>In a small Georgia town in the 1950s, bigoted ...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>M/16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['small', 'georgia', 'town', 'bigoted', 'store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>The Poison Rose</td>\n",
       "      <td>30/05/2019</td>\n",
       "      <td>Inspired by classic film noir, Carson Phillips...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10203.0</td>\n",
       "      <td>M/14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['inspired', 'classic', 'film', 'noir', 'carso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>Da hong denglong gaogao gua</td>\n",
       "      <td>22/01/1993</td>\n",
       "      <td>A young woman becomes the fourth wife of a wea...</td>\n",
       "      <td>8.1</td>\n",
       "      <td>33563.0</td>\n",
       "      <td>M/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['young', 'woman', 'becomes', 'fourth', 'wife'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5486</th>\n",
       "      <td>Requiem pro panenku</td>\n",
       "      <td>01/02/1992</td>\n",
       "      <td>Fourteen-year-old Marika was placed in a socia...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['fourteen', 'year', 'old', 'marika', 'placed'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>Mao tou ying yu xiao fei xiang</td>\n",
       "      <td>12/12/1984</td>\n",
       "      <td>Two retired thieves are blackmailed into teach...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['two', 'retired', 'thief', 'blackmailed', 'te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8224 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name Date Published  \\\n",
       "3650                                 Heatwave     17/01/2022   \n",
       "4272  Vanity Fair: Killers Kill, Dead Men Die            NaN   \n",
       "7366                             Rogue Trader     27/10/2021   \n",
       "4186                  My Beautiful Laundrette     03/02/1989   \n",
       "1630                                The Caddy     03/03/2021   \n",
       "...                                       ...            ...   \n",
       "5483                              Paris Trout     29/11/1991   \n",
       "5484                          The Poison Rose     30/05/2019   \n",
       "5485              Da hong denglong gaogao gua     22/01/1993   \n",
       "5486                      Requiem pro panenku     01/02/1992   \n",
       "4111           Mao tou ying yu xiao fei xiang     12/12/1984   \n",
       "\n",
       "                                            Description  Rating  Rating Count  \\\n",
       "3650  Claire, an ambitious young woman, starts worki...     5.0         925.0   \n",
       "4272  The most ambitious portfolio in the thirteen-y...     5.1         257.0   \n",
       "7366  Ambitious investment banker Tom Walker is cata...     6.2          85.0   \n",
       "4186  An ambitious Pakistani Briton and his white bo...     6.8       16522.0   \n",
       "1630  When an ambitious young Mexican diplomat loses...     NaN           NaN   \n",
       "...                                                 ...     ...           ...   \n",
       "5483  In a small Georgia town in the 1950s, bigoted ...     6.4        1593.0   \n",
       "5484  Inspired by classic film noir, Carson Phillips...     4.7       10203.0   \n",
       "5485  A young woman becomes the fourth wife of a wea...     8.1       33563.0   \n",
       "5486  Fourteen-year-old Marika was placed in a socia...     7.3         360.0   \n",
       "4111  Two retired thieves are blackmailed into teach...     5.8         161.0   \n",
       "\n",
       "     Content Rating  Action  Adult  Adventure  Animation  ...  Reality-TV  \\\n",
       "3650              R       0      0          0          0  ...           0   \n",
       "4272            NaN       0      0          0          0  ...           0   \n",
       "7366            NaN       0      0          0          0  ...           0   \n",
       "4186           M/16       0      0          0          0  ...           0   \n",
       "1630            NaN       0      0          0          0  ...           0   \n",
       "...             ...     ...    ...        ...        ...  ...         ...   \n",
       "5483           M/16       0      0          0          0  ...           0   \n",
       "5484           M/14       0      0          0          0  ...           0   \n",
       "5485           M/12       0      0          0          0  ...           0   \n",
       "5486            NaN       0      0          0          0  ...           0   \n",
       "4111            NaN       1      0          0          0  ...           0   \n",
       "\n",
       "      Romance  Sci-Fi  Short  Sport  Talk-Show  Thriller  War  Western  \\\n",
       "3650        0       0      0      0          0         1    0        0   \n",
       "4272        0       0      1      0          0         0    0        0   \n",
       "7366        0       0      0      0          0         1    0        0   \n",
       "4186        1       0      0      0          0         0    0        0   \n",
       "1630        0       0      1      0          0         1    0        0   \n",
       "...       ...     ...    ...    ...        ...       ...  ...      ...   \n",
       "5483        0       0      0      0          0         0    0        0   \n",
       "5484        0       0      0      0          0         1    0        0   \n",
       "5485        1       0      0      0          0         0    0        0   \n",
       "5486        0       0      0      0          0         1    0        0   \n",
       "4111        0       0      0      0          0         0    0        0   \n",
       "\n",
       "                                  Description Tokenized  \n",
       "3650  ['claire', 'ambitious', 'young', 'woman', 'sta...  \n",
       "4272  ['ambitious', 'portfolio', 'thirteen', 'year',...  \n",
       "7366  ['ambitious', 'investment', 'banker', 'tom', '...  \n",
       "4186  ['ambitious', 'pakistani', 'briton', 'white', ...  \n",
       "1630  ['ambitious', 'young', 'mexican', 'diplomat', ...  \n",
       "...                                                 ...  \n",
       "5483  ['small', 'georgia', 'town', 'bigoted', 'store...  \n",
       "5484  ['inspired', 'classic', 'film', 'noir', 'carso...  \n",
       "5485  ['young', 'woman', 'becomes', 'fourth', 'wife'...  \n",
       "5486  ['fourteen', 'year', 'old', 'marika', 'placed'...  \n",
       "4111  ['two', 'retired', 'thief', 'blackmailed', 'te...  \n",
       "\n",
       "[8224 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0864d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xaviersantos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def tokenize_input(user_input):\n",
    "    user_input = RegexpTokenizer(r'[a-zA-z]+').tokenize(user_input)\n",
    "    user_input = [t.lower() for t in user_input]\n",
    "    user_input = [t for t in user_input if not t in list(string.punctuation)]\n",
    "    user_input = [t for t in user_input if not t in stopwords.words(\"english\")]\n",
    "    user_input = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in user_input]\n",
    "    return user_input\n",
    "\n",
    "# Load movie data\n",
    "movies_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Tokenize movie descriptions\n",
    "tokenized_descriptions = movies_df['Description Tokenized'].apply(tokenize_input)\n",
    "\n",
    "# Tokenize user input\n",
    "user_input = 'An ambitious young executive chooses a'\n",
    "tokenized_user_input = tokenize_input(user_input)\n",
    "\n",
    "# TF-IDF similarity\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_bow = vectorizer.fit_transform(movies_df['Description Tokenized'])\n",
    "user_input_tfidf_bow = vectorizer.transform([user_input])\n",
    "tfidf_scores = cosine_similarity(user_input_tfidf_bow, tfidf_bow)\n",
    "\n",
    "# Word2Vec similarity\n",
    "w2v_model = KeyedVectors.load_word2vec_format('../models/word2vec.bin', binary=True)\n",
    "w2v_scores = []\n",
    "for description in tokenized_descriptions:\n",
    "    description_vectors = [w2v_model[word] for word in description if word in w2v_model.vocab]\n",
    "    user_input_vectors = [w2v_model[word] for word in tokenized_user_input if word in w2v_model.vocab]\n",
    "    similarity_matrix = np.inner(description_vectors, user_input_vectors)\n",
    "    w2v_scores.append(np.sum(similarity_matrix) / (np.linalg.norm(description_vectors, axis=1).sum() * np.linalg.norm(user_input_vectors, axis=1).sum()))\n",
    "\n",
    "# Combine all similarity scores\n",
    "similarity_scores = np.column_stack((tfidf_scores, rake_scores, w2v_scores))\n",
    "\n",
    "# Rank movies based on similarity\n",
    "ranked_movies = movies_df.iloc[similarity_scores.mean(axis=1).argsort()[::-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125df5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summa==1.2.0\n",
      "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /Users/xaviersantos/opt/anaconda3/lib/python3.9/site-packages (from summa==1.2.0) (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /Users/xaviersantos/opt/anaconda3/lib/python3.9/site-packages (from scipy>=0.19->summa==1.2.0) (1.21.5)\n",
      "Building wheels for collected packages: summa\n",
      "  Building wheel for summa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54390 sha256=f88d5357a697aad2db8cb1962107728a8e2e3230b24005d957e85a55904e5c5f\n",
      "  Stored in directory: /Users/xaviersantos/Library/Caches/pip/wheels/ed/2c/5f/a0ccc5955d44d2cea78729f4425e73f818d2629517f7af0f8b\n",
      "Successfully built summa\n",
      "Installing collected packages: summa\n",
      "Successfully installed summa-1.2.0\n"
     ]
    }
   ],
   "source": [
    "ranked_movies\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
