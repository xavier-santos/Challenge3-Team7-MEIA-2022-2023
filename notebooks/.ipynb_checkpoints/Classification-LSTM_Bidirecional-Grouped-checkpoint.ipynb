{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268a05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.20.0-cp39-cp39-win_amd64.whl (746 kB)\n",
      "     -------------------------------------- 746.7/746.7 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\carol\\anaconda3\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\carol\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6674ffe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "146/146 [==============================] - 295s 2s/step - loss: 0.2981 - accuracy: 0.2780 - val_loss: 0.2731 - val_accuracy: 0.2563\n",
      "Epoch 2/10\n",
      "146/146 [==============================] - 221s 2s/step - loss: 0.2561 - accuracy: 0.3541 - val_loss: 0.2605 - val_accuracy: 0.2909\n",
      "Epoch 3/10\n",
      "146/146 [==============================] - 205s 1s/step - loss: 0.2315 - accuracy: 0.4258 - val_loss: 0.2451 - val_accuracy: 0.3642\n",
      "Epoch 4/10\n",
      "146/146 [==============================] - 195s 1s/step - loss: 0.2062 - accuracy: 0.4873 - val_loss: 0.2465 - val_accuracy: 0.3565\n",
      "Epoch 5/10\n",
      "146/146 [==============================] - 196s 1s/step - loss: 0.1865 - accuracy: 0.5275 - val_loss: 0.2511 - val_accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "146/146 [==============================] - 198s 1s/step - loss: 0.1657 - accuracy: 0.5764 - val_loss: 0.2508 - val_accuracy: 0.3969\n",
      "Epoch 7/10\n",
      "146/146 [==============================] - 207s 1s/step - loss: 0.1483 - accuracy: 0.6126 - val_loss: 0.2626 - val_accuracy: 0.3815\n",
      "Epoch 8/10\n",
      "146/146 [==============================] - 205s 1s/step - loss: 0.1341 - accuracy: 0.6476 - val_loss: 0.2645 - val_accuracy: 0.3738\n",
      "Epoch 9/10\n",
      "146/146 [==============================] - 204s 1s/step - loss: 0.1203 - accuracy: 0.6508 - val_loss: 0.2796 - val_accuracy: 0.3854\n",
      "Epoch 10/10\n",
      "146/146 [==============================] - 222s 2s/step - loss: 0.1078 - accuracy: 0.6611 - val_loss: 0.2876 - val_accuracy: 0.3603\n",
      "89/89 [==============================] - 35s 391ms/step - loss: 0.3243 - accuracy: 0.3387\n",
      "Loss: 0.3242824375629425\n",
      "Accuracy: 0.33873239159584045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Pré-processar os dados\n",
    "# Carregue seus datasets balanceados\n",
    "train_data = pd.read_csv('../data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "test_data = pd.read_csv('../data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "\n",
    "category_columns = train_data.columns.drop(['Name', 'Description', 'Combined'])\n",
    "\n",
    "# Defina os parâmetros de pré-processamento\n",
    "max_features = 10000  # Número máximo de palavras a serem usadas (palavras mais frequentes)\n",
    "maxlen = 200  # Número máximo de palavras no texto\n",
    "\n",
    "# Tokenize os textos\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_data['Combined'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Combined'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Combined'])\n",
    "\n",
    "# Padronize os textos\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Obtenha os labels one-hot encoded\n",
    "y_train = train_data[category_columns].values\n",
    "y_test = test_data[category_columns].values\n",
    "\n",
    "# 2. Construir o modelo\n",
    "embedding_dim = 128  # Dimensão do vetor de embedding\n",
    "lstm_units = 64  # Unidades LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_features, embedding_dim, input_length=maxlen),\n",
    "    Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "    Bidirectional(LSTM(lstm_units)),\n",
    "    Dense(len(category_columns), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 3. Treinar o modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1132640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 41s 427ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (micro): 0.47\n",
      "F1-score (macro): 0.29\n",
      "Precision (micro): 0.59\n",
      "Precision (macro): 0.45\n",
      "Recall (micro): 0.39\n",
      "Recall (macro): 0.24\n",
      "89/89 [==============================] - 37s 412ms/step\n",
      "Class: Action\n",
      "F1-score: 0.42\n",
      "AUC-PR: 0.48\n",
      "\n",
      "\n",
      "Class: Adventure\n",
      "F1-score: 0.45\n",
      "AUC-PR: 0.43\n",
      "\n",
      "\n",
      "Class: Animation\n",
      "F1-score: 0.21\n",
      "AUC-PR: 0.31\n",
      "\n",
      "\n",
      "Class: Biography\n",
      "F1-score: 0.03\n",
      "AUC-PR: 0.09\n",
      "\n",
      "\n",
      "Class: Comedy\n",
      "F1-score: 0.53\n",
      "AUC-PR: 0.59\n",
      "\n",
      "\n",
      "Class: Crime\n",
      "F1-score: 0.51\n",
      "AUC-PR: 0.54\n",
      "\n",
      "\n",
      "Class: Documentary\n",
      "F1-score: 0.30\n",
      "AUC-PR: 0.32\n",
      "\n",
      "\n",
      "Class: Drama\n",
      "F1-score: 0.71\n",
      "AUC-PR: 0.73\n",
      "\n",
      "\n",
      "Class: Family\n",
      "F1-score: 0.12\n",
      "AUC-PR: 0.19\n",
      "\n",
      "\n",
      "Class: Fantasy\n",
      "F1-score: 0.01\n",
      "AUC-PR: 0.16\n",
      "\n",
      "\n",
      "Class: History\n",
      "F1-score: 0.08\n",
      "AUC-PR: 0.15\n",
      "\n",
      "\n",
      "Class: Horror\n",
      "F1-score: 0.40\n",
      "AUC-PR: 0.44\n",
      "\n",
      "\n",
      "Class: Music\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.14\n",
      "\n",
      "\n",
      "Class: Musical\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.07\n",
      "\n",
      "\n",
      "Class: Mystery\n",
      "F1-score: 0.10\n",
      "AUC-PR: 0.19\n",
      "\n",
      "\n",
      "Class: Romance\n",
      "F1-score: 0.34\n",
      "AUC-PR: 0.38\n",
      "\n",
      "\n",
      "Class: Sci-Fi\n",
      "F1-score: 0.31\n",
      "AUC-PR: 0.35\n",
      "\n",
      "\n",
      "Class: Short\n",
      "F1-score: 0.48\n",
      "AUC-PR: 0.47\n",
      "\n",
      "\n",
      "Class: Thriller\n",
      "F1-score: 0.17\n",
      "AUC-PR: 0.24\n",
      "\n",
      "\n",
      "Class: War\n",
      "F1-score: 0.28\n",
      "AUC-PR: 0.29\n",
      "\n",
      "\n",
      "Class: Western\n",
      "F1-score: 0.54\n",
      "AUC-PR: 0.50\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-score (micro): {:.2f}\".format(f1_micro))\n",
    "print(\"F1-score (macro): {:.2f}\".format(f1_macro))\n",
    "print(\"Precision (micro): {:.2f}\".format(precision_micro))\n",
    "print(\"Precision (macro): {:.2f}\".format(precision_macro))\n",
    "print(\"Recall (micro): {:.2f}\".format(recall_micro))\n",
    "print(\"Recall (macro): {:.2f}\".format(recall_macro))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "f1_scores_per_class = f1_score(y_test, np.round(y_pred), average=None)\n",
    "auc_pr_per_class = average_precision_score(y_test, y_pred, average=None)\n",
    "for i, category in enumerate(category_columns):\n",
    "    print(\"Class: {}\".format(category))\n",
    "    print(\"F1-score: {:.2f}\".format(f1_scores_per_class[i]))\n",
    "    print(\"AUC-PR: {:.2f}\".format(auc_pr_per_class[i]))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
