{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268a05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.20.0-cp39-cp39-win_amd64.whl (746 kB)\n",
      "     -------------------------------------- 746.7/746.7 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\carol\\anaconda3\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\carol\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6674ffe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 117s 878ms/step - loss: 0.3172 - accuracy: 0.2628 - val_loss: 0.2735 - val_accuracy: 0.3225\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 104s 853ms/step - loss: 0.2853 - accuracy: 0.2647 - val_loss: 0.2740 - val_accuracy: 0.3225\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 101s 826ms/step - loss: 0.2836 - accuracy: 0.2652 - val_loss: 0.2693 - val_accuracy: 0.3295\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 102s 837ms/step - loss: 0.2675 - accuracy: 0.3431 - val_loss: 0.2673 - val_accuracy: 0.3480\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 106s 872ms/step - loss: 0.2437 - accuracy: 0.4304 - val_loss: 0.2570 - val_accuracy: 0.4130\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 107s 874ms/step - loss: 0.2189 - accuracy: 0.4975 - val_loss: 0.2571 - val_accuracy: 0.3921\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 109s 895ms/step - loss: 0.1943 - accuracy: 0.5438 - val_loss: 0.2583 - val_accuracy: 0.4107\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 109s 894ms/step - loss: 0.1718 - accuracy: 0.5895 - val_loss: 0.2656 - val_accuracy: 0.4153\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 113s 931ms/step - loss: 0.1540 - accuracy: 0.6132 - val_loss: 0.2678 - val_accuracy: 0.4084\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 103s 846ms/step - loss: 0.1362 - accuracy: 0.6261 - val_loss: 0.2798 - val_accuracy: 0.4107\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.3329 - accuracy: 0.3243\n",
      "Loss: 0.3328833281993866\n",
      "Accuracy: 0.3243435025215149\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Pré-processar os dados\n",
    "# Carregue seus datasets balanceados\n",
    "train_data = pd.read_csv('../data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "test_data = pd.read_csv('../data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "\n",
    "category_columns = train_data.columns.drop(['Name', 'Description', 'Combined'])\n",
    "\n",
    "# Defina os parâmetros de pré-processamento\n",
    "max_features = 10000  # Número máximo de palavras a serem usadas (palavras mais frequentes)\n",
    "maxlen = 200  # Número máximo de palavras no texto\n",
    "\n",
    "# Tokenize os textos\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_data['Combined'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Combined'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Combined'])\n",
    "\n",
    "# Padronize os textos\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Obtenha os labels one-hot encoded\n",
    "y_train = train_data[category_columns].values\n",
    "y_test = test_data[category_columns].values\n",
    "\n",
    "# 2. Construir o modelo\n",
    "embedding_dim = 128  # Dimensão do vetor de embedding\n",
    "lstm_units = 64  # Unidades LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_features, embedding_dim, input_length=maxlen),\n",
    "    Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "    Bidirectional(LSTM(lstm_units)),\n",
    "    Dense(len(category_columns), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 3. Treinar o modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1132640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 17s 309ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (micro): 0.45\n",
      "F1-score (macro): 0.21\n",
      "Precision (micro): 0.56\n",
      "Precision (macro): 0.33\n",
      "Recall (micro): 0.37\n",
      "Recall (macro): 0.18\n",
      "45/45 [==============================] - 14s 305ms/step\n",
      "Class: Action\n",
      "F1-score: 0.41\n",
      "AUC-PR: 0.50\n",
      "\n",
      "\n",
      "Class: Adventure\n",
      "F1-score: 0.46\n",
      "AUC-PR: 0.47\n",
      "\n",
      "\n",
      "Class: Animation\n",
      "F1-score: 0.16\n",
      "AUC-PR: 0.23\n",
      "\n",
      "\n",
      "Class: Biography\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.14\n",
      "\n",
      "\n",
      "Class: Comedy\n",
      "F1-score: 0.55\n",
      "AUC-PR: 0.57\n",
      "\n",
      "\n",
      "Class: Crime\n",
      "F1-score: 0.51\n",
      "AUC-PR: 0.54\n",
      "\n",
      "\n",
      "Class: Documentary\n",
      "F1-score: 0.23\n",
      "AUC-PR: 0.16\n",
      "\n",
      "\n",
      "Class: Drama\n",
      "F1-score: 0.68\n",
      "AUC-PR: 0.70\n",
      "\n",
      "\n",
      "Class: Family\n",
      "F1-score: 0.18\n",
      "AUC-PR: 0.18\n",
      "\n",
      "\n",
      "Class: Fantasy\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.14\n",
      "\n",
      "\n",
      "Class: History\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.14\n",
      "\n",
      "\n",
      "Class: Horror\n",
      "F1-score: 0.28\n",
      "AUC-PR: 0.36\n",
      "\n",
      "\n",
      "Class: Music\n",
      "F1-score: 0.08\n",
      "AUC-PR: 0.25\n",
      "\n",
      "\n",
      "Class: Musical\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.11\n",
      "\n",
      "\n",
      "Class: Mystery\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.21\n",
      "\n",
      "\n",
      "Class: Romance\n",
      "F1-score: 0.31\n",
      "AUC-PR: 0.36\n",
      "\n",
      "\n",
      "Class: Sci-Fi\n",
      "F1-score: 0.17\n",
      "AUC-PR: 0.38\n",
      "\n",
      "\n",
      "Class: Thriller\n",
      "F1-score: 0.23\n",
      "AUC-PR: 0.24\n",
      "\n",
      "\n",
      "Class: War\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.24\n",
      "\n",
      "\n",
      "Class: Western\n",
      "F1-score: 0.00\n",
      "AUC-PR: 0.14\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-score (micro): {:.2f}\".format(f1_micro))\n",
    "print(\"F1-score (macro): {:.2f}\".format(f1_macro))\n",
    "print(\"Precision (micro): {:.2f}\".format(precision_micro))\n",
    "print(\"Precision (macro): {:.2f}\".format(precision_macro))\n",
    "print(\"Recall (micro): {:.2f}\".format(recall_micro))\n",
    "print(\"Recall (macro): {:.2f}\".format(recall_macro))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "f1_scores_per_class = f1_score(y_test, np.round(y_pred), average=None)\n",
    "auc_pr_per_class = average_precision_score(y_test, y_pred, average=None)\n",
    "for i, category in enumerate(category_columns):\n",
    "    print(\"Class: {}\".format(category))\n",
    "    print(\"F1-score: {:.2f}\".format(f1_scores_per_class[i]))\n",
    "    print(\"AUC-PR: {:.2f}\".format(auc_pr_per_class[i]))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
