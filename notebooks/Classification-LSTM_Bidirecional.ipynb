{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268a05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.20.0-cp39-cp39-win_amd64.whl (746 kB)\n",
      "     -------------------------------------- 746.7/746.7 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\carol\\anaconda3\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\carol\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef4e0e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 159s 780ms/step - loss: 0.2538 - accuracy: 0.2793 - val_loss: 0.2188 - val_accuracy: 0.2876\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 108s 721ms/step - loss: 0.2129 - accuracy: 0.2809 - val_loss: 0.2149 - val_accuracy: 0.2481\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 106s 704ms/step - loss: 0.2065 - accuracy: 0.2768 - val_loss: 0.2089 - val_accuracy: 0.2481\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 108s 718ms/step - loss: 0.1986 - accuracy: 0.3340 - val_loss: 0.2036 - val_accuracy: 0.3102\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 118s 786ms/step - loss: 0.1904 - accuracy: 0.3756 - val_loss: 0.2029 - val_accuracy: 0.3045\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 132s 879ms/step - loss: 0.1810 - accuracy: 0.4110 - val_loss: 0.1994 - val_accuracy: 0.3195\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 104s 695ms/step - loss: 0.1681 - accuracy: 0.4645 - val_loss: 0.1983 - val_accuracy: 0.3647\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 104s 692ms/step - loss: 0.1532 - accuracy: 0.5236 - val_loss: 0.2032 - val_accuracy: 0.3571\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 104s 692ms/step - loss: 0.1406 - accuracy: 0.5489 - val_loss: 0.2078 - val_accuracy: 0.3590\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 105s 698ms/step - loss: 0.1279 - accuracy: 0.5786 - val_loss: 0.2135 - val_accuracy: 0.3534\n",
      "91/91 [==============================] - 19s 212ms/step - loss: 0.2345 - accuracy: 0.3422\n",
      "Loss: 0.23454779386520386\n",
      "Accuracy: 0.34215956926345825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Pré-processar os dados\n",
    "# Carregue seus datasets balanceados\n",
    "train_data = pd.read_csv('../data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "test_data = pd.read_csv('../data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "\n",
    "category_columns = train_data.columns.drop(['Name', 'Description', 'Combined'])\n",
    "\n",
    "# Defina os parâmetros de pré-processamento\n",
    "max_features = 10000  # Número máximo de palavras a serem usadas (palavras mais frequentes)\n",
    "maxlen = 200  # Número máximo de palavras no texto\n",
    "\n",
    "# Tokenize os textos\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_data['Combined'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Combined'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Combined'])\n",
    "\n",
    "# Padronize os textos\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Obtenha os labels one-hot encoded\n",
    "y_train = train_data[category_columns].values\n",
    "y_test = test_data[category_columns].values\n",
    "\n",
    "# 2. Construir o modelo\n",
    "embedding_dim = 128  # Dimensão do vetor de embedding\n",
    "lstm_units = 64  # Unidades LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_features, embedding_dim, input_length=maxlen),\n",
    "    Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "    Bidirectional(LSTM(lstm_units)),\n",
    "    Dense(len(category_columns), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 3. Treinar o modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a94a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 22s 221ms/step\n",
      "F1-score (micro): 0.41\n",
      "F1-score (macro): 0.15\n",
      "Precision (micro): 0.62\n",
      "Precision (macro): 0.25\n",
      "Recall (micro): 0.31\n",
      "Recall (macro): 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'average_precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13552\\627113742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mf1_scores_per_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mauc_pr_per_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'average_precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-score (micro): {:.2f}\".format(f1_micro))\n",
    "print(\"F1-score (macro): {:.2f}\".format(f1_macro))\n",
    "print(\"Precision (micro): {:.2f}\".format(precision_micro))\n",
    "print(\"Precision (macro): {:.2f}\".format(precision_macro))\n",
    "print(\"Recall (micro): {:.2f}\".format(recall_micro))\n",
    "print(\"Recall (macro): {:.2f}\".format(recall_macro))\n",
    "\n",
    "f1_scores_per_class = f1_score(y_test, np.round(y_pred), average=None)\n",
    "auc_pr_per_class = average_precision_score(y_test, y_pred, average=None)\n",
    "for i, category in enumerate(category_columns):\n",
    "    print(\"Class: {}\".format(category))\n",
    "    print(\"F1-score: {:.2f}\".format(f1_scores_per_class[i]))\n",
    "    print(\"AUC-PR: {:.2f}\".format(auc_pr_per_class[i]))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
