{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52a456d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:54:03.649798Z",
     "start_time": "2023-04-17T16:54:00.481440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# 1. Pré-processar os dados\n",
    "# Carregue seus datasets balanceados\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "category_columns = train_data.columns.drop(['Name', 'Description Tokenized'])\n",
    "\n",
    "# Tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Hiperparâmetros\n",
    "max_len = 128\n",
    "batch_size = 16\n",
    "epochs = 4\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Classe Dataset personalizada\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Combined']\n",
    "        labels = self.data.iloc[idx][category_columns]  # Ajuste de acordo com os gêneros no seu conjunto de dados\n",
    "\n",
    "        tokens = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokens['input_ids'][0],\n",
    "            'attention_mask': tokens['attention_mask'][0],\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Função de perda de entropia cruzada binária\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def evaluate(model, data_loader, loss_fn, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.sigmoid(logits).cpu().numpy())\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Prepare os DataLoaders\n",
    "train_dataset = MovieDataset(train_data, tokenizer, max_len)\n",
    "test_dataset = MovieDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Carregue o modelo pré-treinado e modifique a camada de saída\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3).to(device)\n",
    "model.classifier = nn.Linear(model.config.hidden_size, 9).to(device)  # Ajuste '3' ao número de gêneros no seu conjunto de dados\n",
    "\n",
    "# Otimizador e programador\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Treinamento e avaliação\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train loss: {train_loss}\")\n",
    "\n",
    "    test_loss = evaluate(model, test_loader, loss_fn, device)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Test loss: {test_loss}\")\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "predictions = predict(model, test_loader, device)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65950678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:56:16.034610Z",
     "start_time": "2023-04-17T16:56:16.017057Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54fdd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro: 0.5634552851835604\n",
      "F1 Samples: 0.62287865301884\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Avalie o desempenho do modelo usando a métrica F1\n",
    "test_labels = test_data[category_columns].values  # Ajuste de acordo com os gêneros no seu conjunto de dados\n",
    "f1_macro = f1_score(test_labels, predictions_binary, average='macro')\n",
    "f1_samples = f1_score(test_labels, predictions_binary, average='samples')\n",
    "\n",
    "print(f\"F1 Macro: {f1_macro}\")\n",
    "print(f\"F1 Samples: {f1_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb68e86c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Comedy       0.80      0.53      0.64       502\n",
      "                  Crime       0.81      0.54      0.65       259\n",
      "                  Drama       0.80      0.72      0.76       757\n",
      "                Romance       0.83      0.19      0.31       272\n",
      "   Action and Adventure       0.79      0.58      0.67       450\n",
      "Documentary and History       0.80      0.39      0.52       144\n",
      "   Family and Animation       0.81      0.30      0.44       141\n",
      "     Fantasy and Sci-Fi       0.66      0.42      0.51       154\n",
      "    Horror and Thriller       0.62      0.52      0.57       291\n",
      "\n",
      "              micro avg       0.77      0.53      0.63      2970\n",
      "              macro avg       0.77      0.47      0.56      2970\n",
      "           weighted avg       0.78      0.53      0.62      2970\n",
      "            samples avg       0.78      0.57      0.62      2970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Supondo que test_labels seja um numpy array contendo os rótulos verdadeiros do conjunto de teste\n",
    "report = classification_report(test_labels, predictions_binary, target_names=category_columns, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebfbb706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR : Comedy: 0.7902\n",
      "AUC-PR : Crime: 0.7448\n",
      "AUC-PR : Drama: 0.8399\n",
      "AUC-PR : Romance: 0.6160\n",
      "AUC-PR : Action and Adventure: 0.7937\n",
      "AUC-PR : Documentary and History: 0.6495\n",
      "AUC-PR : Family and Animation: 0.6211\n",
      "AUC-PR : Fantasy and Sci-Fi: 0.5707\n",
      "AUC-PR : Horror and Thriller: 0.6162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Calcular AUC-PR para cada gênero\n",
    "auc_pr_scores = []\n",
    "\n",
    "for i in range(len(category_columns)):\n",
    "    auc_pr = average_precision_score(test_labels[:, i], predictions[:, i])\n",
    "    auc_pr_scores.append(auc_pr)\n",
    "\n",
    "# Imprimir AUC-PR por gênero\n",
    "for genre, score in zip(category_columns, auc_pr_scores):\n",
    "    print(f'AUC-PR : {genre}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "919c55dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusão para Comedy:\n",
      "[[715  67]\n",
      " [234 268]]\n",
      "\n",
      "Matriz de confusão para Crime:\n",
      "[[992  33]\n",
      " [119 140]]\n",
      "\n",
      "Matriz de confusão para Drama:\n",
      "[[389 138]\n",
      " [212 545]]\n",
      "\n",
      "Matriz de confusão para Romance:\n",
      "[[1001   11]\n",
      " [ 220   52]]\n",
      "\n",
      "Matriz de confusão para Action and Adventure:\n",
      "[[766  68]\n",
      " [187 263]]\n",
      "\n",
      "Matriz de confusão para Documentary and History:\n",
      "[[1126   14]\n",
      " [  88   56]]\n",
      "\n",
      "Matriz de confusão para Family and Animation:\n",
      "[[1133   10]\n",
      " [  98   43]]\n",
      "\n",
      "Matriz de confusão para Fantasy and Sci-Fi:\n",
      "[[1097   33]\n",
      " [  90   64]]\n",
      "\n",
      "Matriz de confusão para Horror and Thriller:\n",
      "[[898  95]\n",
      " [139 152]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "# Calcular e imprimir matriz de confusão para cada gênero\n",
    "for i, genre in enumerate(category_columns):\n",
    "    cm = confusion_matrix(test_labels[:, i], predictions_binary[:, i])\n",
    "    print(f'\\nMatriz de confusão para {genre}:')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0053e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusão normalizada para Comedy (%):\n",
      "[[91  9]\n",
      " [47 53]]\n",
      "\n",
      "Matriz de confusão normalizada para Crime (%):\n",
      "[[97  3]\n",
      " [46 54]]\n",
      "\n",
      "Matriz de confusão normalizada para Drama (%):\n",
      "[[74 26]\n",
      " [28 72]]\n",
      "\n",
      "Matriz de confusão normalizada para Romance (%):\n",
      "[[99  1]\n",
      " [81 19]]\n",
      "\n",
      "Matriz de confusão normalizada para Action and Adventure (%):\n",
      "[[92  8]\n",
      " [42 58]]\n",
      "\n",
      "Matriz de confusão normalizada para Documentary and History (%):\n",
      "[[99  1]\n",
      " [61 39]]\n",
      "\n",
      "Matriz de confusão normalizada para Family and Animation (%):\n",
      "[[99  1]\n",
      " [70 30]]\n",
      "\n",
      "Matriz de confusão normalizada para Fantasy and Sci-Fi (%):\n",
      "[[97  3]\n",
      " [58 42]]\n",
      "\n",
      "Matriz de confusão normalizada para Horror and Thriller (%):\n",
      "[[90 10]\n",
      " [48 52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def normalize_confusion_matrix(cm):\n",
    "    normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    return normalized_cm * 100\n",
    "\n",
    "# Calcular e imprimir matriz de confusão normalizada para cada gênero\n",
    "for i, genre in enumerate(category_columns):\n",
    "    cm = confusion_matrix(test_labels[:, i], predictions_binary[:, i])\n",
    "    normalized_cm = normalize_confusion_matrix(cm)\n",
    "    \n",
    "    # Arredondar a matriz normalizada para remover casas decimais\n",
    "    rounded_normalized_cm = np.round(normalized_cm).astype(int)\n",
    "\n",
    "    print(f'\\nMatriz de confusão normalizada para {genre} (%):')\n",
    "    print(rounded_normalized_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
